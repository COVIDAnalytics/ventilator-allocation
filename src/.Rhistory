testPred_2 = predict(model2, newdata = testImputed)
OSR2_2 =1-sum((testPred_2 - test$V9)^2)/sum((test$V9 - mean(train$V9))^2)
# with regularization
model2_cv <- cv.glmnet(as.matrix(trainImputed[,c("V2", "V3", "V4", "V5", "V6", "V7", "V8")]), as.vector(train$V9), alpha = 0., lambda=lambdas)
# optimal lambda has been found
model2_opt = glmnet(as.matrix(trainImputed[,c("V2", "V3", "V4", "V5", "V6", "V7", "V8")]), as.vector(train$V9), alpha = 0., lambda=model2_cv$lambda.min)
trainPred_2_opt = predict(model2_opt, newx=as.matrix(trainImputed[,c("V2", "V3", "V4", "V5", "V6", "V7", "V8")]))
testPred_2_opt = predict(model2_opt, newx=as.matrix(testImputed[,c("V2", "V3", "V4", "V5", "V6", "V7", "V8")]))
R2_2opt = 1 - sum((trainPred_2_opt - train$V9)^2)/sum((train$V9 - mean(train$V9))^2)
OSR2_2opt = 1 - sum((testPred_2_opt - test$V9)^2)/sum((test$V9 - mean(train$V9))^2)
set.seed(144)
rand()
set.seed(144)
runif()
runif(1)
x <- "a1~!@#$%^&*(){}_+:\"<>?,./;'[]-="
gsub("~@#+", "", x)
x
gsub("[~@#+]", "", x)
data = data.frame(name=c("Arthur", "Arthur", "Jackie", "Jourdain") fico=c(1,2,3,4))
data = data.frame(name=c("Arthur", "Arthur", "Jackie", "Jourdain"), fico=c(1,2,3,4))
table(data$name)
which(table(data$name) > 1)
data = data.frame(name=c("Arthur", "Arthur", "Jackie", "Jourdain"), fico=c(1,2,3,4))
which(table(data$name) > 1)
install.packages('lars')
install.packages("lars")
library(lar)
library(lars)
data("iris")
iris
data(prestige)
data = data.frame(X=c(1,2,3,4,5), Y=c(2,4,6,8,10))
data(mtcars)
head(mtcars)
library(tidyverse)
mtcars %>%
select(c(disp, hp, drat, wt, qsec))
mtcars %>%
+ select(c(disp, hp, drat, wt, qsec)) %>%
as.matrix()
mtcars %>% select(c(disp, hp, drat, wt, qsec)) %>% as.matrix()
X = mtcars %>% select(c(disp, hp, drat, wt, qsec)) %>% as.matrix()
Y = mtcars$mpg
lars(X, Y)
lars(X, Y, trace=T)
lars(X, Y, trace=T, type="lar")
model = lars(X, Y, trace=T, type="lar")
model$df
model$lambda
model$mu
model$R2
model$beta
6*9 ==
42
6*9 ==
54
library(ggmap)
library(ggplot2)
library(tidyverse)
library(BBmisc)
library(maptools)
library(ggmap)
library(RColorBrewer)
library(raster)
library(gpclib)
install.packages(c("ggmap", "BBmisc", "maptools", "raster", "gpclib"))
library(ggplot2)
library(tidyverse)
library(BBmisc)
library(maptools)
library(ggmap)
library(RColorBrewer)
library(raster)
library(gpclib)
bostonMap <- get_map(location = c(bottom = 42.22, top = 42.405,
left=-71.2, right=-70.98),
source="stamen",
maptype="toner-background")
ggmap(bostonMap, darken=c(0.6, "white"))
bostonMap <- get_map(location = c(bottom = 42.22, top = 42.405,
left=-71.2, right=-70.98),
source="stamen",
maptype="toner")
ggmap(bostonMap, darken=c(0.6, "white"))
bostonMap <- get_map(location = c(bottom = 42.22, top = 42.405,
left=-71.2, right=-70.98),
source="stamen",
maptype="toner-background",
color="bw")
ggmap(bostonMap, darken=c(0.6, "white"))
ggmap(bostonMap)
bostonMap <- get_map(location = c(bottom = 42.22, top = 42.405,
left=-71.2, right=-70.98),
source="stamen",
maptype="toner",
color="bw")
ggmap(bostonMap)
bostonMap <- get_map(location = c(bottom = 42.22, top = 42.405,
left=-71.2, right=-70.98),
source="stamen",
maptype="toner-2011",
color="bw")
ggmap(bostonMap)
bostonMap <- get_map(location = c(bottom = 42.22, top = 42.405,
left=-71.2, right=-70.98),
source="stamen",
maptype="toner-2011",
color="bw",
force=TRUE)
ggmap(bostonMap)
bostonMap <- get_map(location = c(bottom = 42.22, top = 42.405,
left=-71.2, right=-70.98),
source="stamen",
maptype="toner-background",
color="bw",
force=TRUE)
ggmap(bostonMap)
bostonMap <- get_map(location = c(bottom = 42.22, top = 42.405,
left=-71.2, right=-70.98),
source="google",
maptype="toner-background",
color="bw",
force=TRUE)
bostonMap <- get_map(location = c(bottom = 42.22, top = 42.405,
left=-71.2, right=-70.98),
source="stamen",
maptype="toner-background",
color="bw",
force=TRUE)
ggmap(bostonMap)
bostonMap <- get_map(location = c(bottom = 42.22, top = 42.405,
left=-71.2, right=-70.98),
source="stamen",
maptype="toner-2011",
color="bw",
force=TRUE)
ggmap(bostonMap)
ggmap(bostonMap, darken=c(0.6, "white"))
bostonMap <- get_map(location = c(bottom = 42.22, top = 42.405,
left=-71.2, right=-70.98),
source="stamen",
maptype="toner-lite",
color="bw",
force=TRUE)
ggmap(bostonMap)
area = readShapePoly("~/Dropbox (MIT)/SchoolBuses/Data/ZIP_Codes/ZIP_Codes.shp")
neighborhoods = read.csv("~/Dropbox (MIT)/SchoolBuses/Data/zips-temp.csv") %>%
mutate(ZIP = as.factor(paste("0", as.character(x), sep=""))) %>%
mutate(x = NULL)
area$mergeID = neighborhoods$ID
area = unionSpatialPolygons(area, area$mergeID)
# convert to data frame for ggplot
area.points = fortify(area, region="mergeID")
area.points$id = as.numeric(area.points$id)
area = readShapePoly("~/Dropbox (MIT)/SchoolBuses/Data/ZIP_Codes/ZIP_Codes.shp")
area
install.packages("VIM")
data(sleep, package='VIM')
View(sleep)
str(sleep)
sleep = as.data.frame(sleep)
data(sleep, package='VIM')
library(VIM)
data(tao, package='VIM')
tao = as.data.frame(tao)
summary(tao)
data(sleep, package='VIM')
sleep = as.data.frame(sleep)
summary(sleep)
install.packages("tibble")
install.packages("colorspace")
install.packages("mice")
library(VIM)
data(sleep, package='VIM')
sleep = as.data.frame(sleep)
library(mice)
mice(sleep)
imputed = mice(sleep)
complete(imputed, action=1)
complete(imputed, action=4)
complete(imputed, action=10)
complete(imputed, action=8)
complete(imputed, action=5)
complete(imputed, action=1)
complete(imputed, action=4)
imputed = mice(sleep, m=20, method='cart')
complete(imputed, action=4)
complete(imputed, action=20)
sleep
mean(sleep)
scale(sleep)
scaledsleep = scale(sleep)
scaledsleep = as.data.frame(scale(sleep))
summary(scaledsleep)
std(scaledsleep)
stddev(scaledsleep)
sleep = as.data.frame(scale(sleep))
imputed = mice(sleep, m=20, method='cart')
complete(imputed, action=4)
complete(imputed, action=6)
testdataset = complete(imputed, action=6)
testdataset = complete(imputed, action=1)
cor(testdataset)
lm(BodyWgt ~ ., data=testdataset)
summary(lm(BodyWgt ~ ., data=testdataset))
summary(lm(BrainWgt ~ ., data=testdataset))
summary(lm(NonD ~ ., data=testdataset))
summary(lm(Gest ~ ., data=testdataset))
summary(lm(sleep ~ ., data=testdataset))
summary(lm(Sleep ~ ., data=testdataset))
sleep
sleep
sleep = as.data.frame(sleep)
data(sleep, package='VIM')
sleep
sleep = as.data.frame(sleep)
sleep
subset(sleep, Danger == 3)
as.data.frame(subset(sleep, Danger == 3))
mice(as.data.frame(subset(sleep, Danger == 3)))
library(tidyverse)
library(ggmap)
bostonMap <- get_map(location = c(bottom = 42.22, top = 42.405,
left=-71.2, right=-70.98),
source="stamen",
maptype="toner-lite",
color="bw",
force=TRUE)
data = read_csv("/Volumes/BPS_Data/student_latlons_19_tmp.csv")
ggmap(bostonMap) +
ggplot(aes(x=data$Longitude, y=data$Latitude)) +
geom_point()
ggmap(bostonMap) +
geom_point(aes(x=data$Longitude, y=data$Latitude)) +
ggmap(bostonMap) +
geom_point(aes(x=data$Longitude, y=data$Latitude))
ggmap(bostonMap) +
geom_point(aes(x=Longitude, y=Latitude), data=data)
ggplot() +
geom_point(aes(x=Longitude, y=Latitude), data=data)
data = read_csv("/Volumes/BPS_Data/student_latlons_19_tmp_2.csv")
ggplot() +
geom_point(aes(x=Longitude, y=Latitude), data=data)
ggmap(bostonMap) +
geom_point(aes(x=Longitude, y=Latitude), data=data)
library(tidyverse)
# Extract ESY sites
data = read_csv("/Volumes/BPS_Data/data/2019_solution/esy_assignments_2019.csv")
data %>%
group_by(Site) %>%
summarize(Address  = first(Address)) %>%
head() # write_csv("/Volumes/BPS_Data/data/program_locations/esy_program_addresses.csv")
# Load latitudes and longitudes pulled from Julia
data_latlon =
read_csv("/Volumes/BPS_Data/data/program_locations/esy_program_addresses_full.csv") %>%
select(c(Site, Latitude, Longitude))
# Add lat/lon to each site for which it is defined
data %>%
left_join(data_latlon, by="Site") %>%
head() # write_csv("/Volumes/BPS_Data/esy_assignments_2019_full.csv")
# Load the Strive and fixed site information
strive = read_csv("/Volumes/BPS_Data/data/2019_solution/students_strive_fixed.csv")
schools = data %>%
left_join(strive) %>%
filter(is.na(StriveSite) & is.na(SpecialSite)) %>%
select(-c(StriveSite, SpecialSite)) %>%
group_by(Site) %>%
summarize(number = n()) %>%
filter(number > 80) %>%
select(-number) %>%
as.data.frame()
data %>%
inner_join(schools) %>%
select(StudentNumber)
data %>%
inner_join(schools) %>%
select(StudentNumber) %>%
write_csv("/Volumes/BPS_Data/data/student_locations/esy_students_nostrive.csv")
data %>%
inner_join(schools) %>%
select(StudentNumber) %>%
left_join(locs) %>%
write_csv("/Volumes/BPS_Data/data/student_locations/esy_students_nostrive.csv")
locs = read_csv("/Volumes/BPS_Data/data/student_locations/student_locations_full_19.csv")
data %>%
inner_join(schools) %>%
select(StudentNumber) %>%
left_join(locs) %>%
write_csv("/Volumes/BPS_Data/data/student_locations/esy_students_nostrive.csv")
data %>%
inner_join(schools) %>%
left_join(locs) %>%
write_csv("/Volumes/BPS_Data/data/student_locations/esy_students_nostrive.csv")
data %>%
inner_join(schools) %>%
left_join(locs, by="StudentNumber") %>%
write_csv("/Volumes/BPS_Data/data/student_locations/esy_students_nostrive.csv")
# Extract ESY sites
data = read_csv("/Volumes/BPS_Data/data/2019_solution/esy_assignments_2019.csv")
library(tidyverse)
# Extract ESY sites
data = read_csv("/Volumes/BPS_Data/data/2019_solution/esy_assignments_2019.csv")
data %>%
left_join(locs, by="StudentNumber") %>%
write_csv("/Volumes/BPS_Data/data/input_data/student_list.csv")
locs = read_csv("/Volumes/BPS_Data/data/student_locations/student_locations_full_19.csv")
data %>%
left_join(locs, by="StudentNumber") %>%
write_csv("/Volumes/BPS_Data/data/input_data/student_list.csv")
library(tidyverse)
students = read_csv("/Volumes/BPS_Data/data/input_data/student_list.csv")
sublist = read_csv("/Volumes/BPS_Data/data/small_example/studentlist_emanuel.csv")
students = sublist %>%
left_join(students)
students %>%
write_csv("/Volumes/BPS_Data/data/small_example/student_list.csv")
library(tidyverse)
students = read_csv("/Volumes/BPS_Data/data/input_data/student_list.csv")
subsublist = read_csv("/Volumes/BPS_Data/data/small_example/emanuel_updatelist.csv")
sublist = read_csv("/Volumes/BPS_Data/data/small_example/studentlist_emanuel.csv") %>% select(StudentNumber)
subsublist = read_csv("/Volumes/BPS_Data/data/small_example/emanuel_updatelist.csv") %>% select(StudentNumber)
sublist %>%
filter(!(StudentNumber %in% subsublist$StudentNumber)) %>%
nrow()
subsublist %>% inner_join(sublist)
subsublist %>% inner_join(sublist) %>% nrow()
unique(subsublist$StudentNumber)
unique(subsublist$StudentNumber) %>% nrow()
unique(subsublist$StudentNumber) %>% n()
unique(subsublist$StudentNumber) %>% as.data.frame() %>% nrow()
# Remove updates over time
sublist = sublist %>%
filter(!(StudentNumber %in% subsublist$StudentNumber)) %>%
nrow()
students = sublist %>%
left_join(students)
# Remove updates over time
sublist = sublist %>%
filter(!(StudentNumber %in% subsublist$StudentNumber))
sublist = read_csv("/Volumes/BPS_Data/data/small_example/studentlist_emanuel.csv") %>% select(StudentNumber)
subsublist = read_csv("/Volumes/BPS_Data/data/small_example/emanuel_updatelist.csv") %>% select(StudentNumber)
# Remove updates over time
sublist = sublist %>%
filter(!(StudentNumber %in% subsublist$StudentNumber))
students = sublist %>%
left_join(students)
students %>%
write_csv("/Volumes/BPS_Data/data/small_example/student_list.csv")
library(tidyverse)
# 2019 solution
data = read_csv("~/Dropbox (MIT)/ESY/Data/data/2019_solution/esy_assignments_2019.csv")
# Student locations
locs = read_csv("~/Dropbox (MIT)/ESY/Data/data/student_locations/student_locations_full_19.csv")
# Build the student list
students = data %>%
left_join(locs, by="StudentNumber") %>%
filter(!(Site %in% c("Home", "#N/A", "None", "Custodial Site", "Wentworth University"))) %>%
mutate(RequiredSite = ifelse(Site %in% c("Carter School", "McKinley South End Academy"), Site, "General"))
# Build the student list
students = data %>%
left_join(locs, by="StudentNumber") %>%
filter(!(Site %in% c("Home", "#N/A", "None", "Custodial Site", "Wentworth University"))) %>%
mutate(RequiredSite = ifelse(Site %in% c("Carter School", "McKinley South End Academy"), Site, "General"))
students %>%
write_csv("~/Dropbox (MIT)/ESY/Data/data/input_data/student_list.csv")
# Build the cohort list
students %>%
filter(SN %in% c("D4", "P4", "M4", "X4", "Y4", "E4", "E3")) %>%
select(StudentNumber, RegularSchoolCode) %>%
write_csv("~/Dropbox (MIT)/ESY/Data/data/input_data/cohort_list.csv")
# 2019 solution
data = read_csv("~/Dropbox (MIT)/ESY/Data/data/2019_solution/esy_assignments_2019.csv")
# 2019 solution
data = read_csv("~/Dropbox (MIT)/ESY/Data/data/2019_solution/esy_assignments_2019.csv")
# 2019 solution
data = read_csv("~/Dropbox (MIT)/ESY/Data/data/2019_solution/esy_assignments_2019.csv")
# 2019 solution
data = read_csv("~/Dropbox (MIT)/ESY/Data/data/2019_solution/esy_assignments_2019.csv", cols(ServicesOnly = col_character()))
# 2019 solution
data = read_csv("~/Dropbox (MIT)/ESY/Data/data/2019_solution/esy_assignments_2019.csv", col_types = cols(ServicesOnly = col_character()))
# Student locations
locs = read_csv("~/Dropbox (MIT)/ESY/Data/data/student_locations/student_locations_full_19.csv")
data %>%
summary()
# Build the student list
students = data %>%
left_join(locs, by="StudentNumber") %>%
filter(!(Site %in% c("Home", "#N/A", "None", "Custodial Site", "Wentworth University"))) %>%
filter(ServicesOnly == "") %>%
mutate(RequiredSite = ifelse(Site %in% c("Carter School", "McKinley South End Academy"), Site, "General"))
data$ServicesOnly[1]
# Build the student list
students = data %>%
left_join(locs, by="StudentNumber") %>%
filter(!(Site %in% c("Home", "#N/A", "None", "Custodial Site", "Wentworth University"))) %>%
filter(is.na(ServicesOnly)) %>%
mutate(RequiredSite = ifelse(Site %in% c("Carter School", "McKinley South End Academy"), Site, "General"))
students %>%
write_csv("~/Dropbox (MIT)/ESY/Data/data/input_data/student_list.csv")
# Build the cohort list
students %>%
filter(SN %in% c("D4", "P4", "M4", "X4", "Y4", "E4", "E3")) %>%
select(StudentNumber, RegularSchoolCode) %>%
write_csv("~/Dropbox (MIT)/ESY/Data/data/input_data/cohort_list.csv")
# 2019 solution
data = read_csv("~/Dropbox (MIT)/ESY/Data/data/2019_solution/esy_assignments_2019.csv", col_types = cols(ServicesOnly = col_character()))
library(tidyverse)
# 2019 solution
data = read_csv("~/Dropbox (MIT)/ESY/Data/data/2019_solution/esy_assignments_2019.csv", col_types = cols(ServicesOnly = col_character()))
# Student locations
locs = read_csv("~/Dropbox (MIT)/ESY/Data/data/student_locations/student_locations_full_19.csv")
# Build the student list
students = data %>%
left_join(locs, by="StudentNumber") %>%
filter(!(Site %in% c("Home", "#N/A", "None", "Custodial Site", "Wentworth University", "Digital Imaging at English High", "Goodwill Program"))) %>%
filter(is.na(ServicesOnly)) %>%
mutate(RequiredSite = ifelse(Site %in% c("Carter School", "McKinley South End Academy"), Site, "General")) %>%
mutate(RequiredSite = sub(" .*", "", RequiredSite))
students %>%
write_csv("~/Dropbox (MIT)/ESY/Data/data/input_data/student_list.csv")
# Build the restrictions list
restrictions = data.frame(
RequiredSite = c("General", "Carter", "McKinley"),
School1 = c("Carter School", "Carter School",
"McKinley South End Academy"),
School2 = c("McKinley South End Academy", "", ""),
School3 = c("", "", ""),
IncludeOrExclude = c(0, 1, 1)
)
restrictions %>%
write_csv("~/Dropbox (MIT)/ESY/Data/data/input_data/restrictions.csv")
# Build the cohort list
students %>%
filter(SN %in% c("D4", "P4", "M4", "X4", "Y4", "E4", "E3")) %>%
select(StudentNumber, RegularSchoolCode) %>%
write_csv("~/Dropbox (MIT)/ESY/Data/data/input_data/cohort_list.csv")
library(tidyverse)
# 2019 solution
data = read_csv("~/Dropbox (MIT)/ESY/Data/data/2019_solution/esy_assignments_2019.csv", col_types = cols(ServicesOnly = col_character()))
# Student locations
locs = read_csv("~/Dropbox (MIT)/ESY/Data/data/student_locations/student_locations_full_19.csv")
# Build the student list
students = data %>%
left_join(locs, by="StudentNumber") %>%
filter(!(Site %in% c("Home", "#N/A", "None", "Custodial Site", "Wentworth University", "Digital Imaging at English High", "Goodwill Program"))) %>%
filter(is.na(ServicesOnly)) %>%
mutate(RequiredSite = ifelse(Site %in% c("Carter School", "McKinley South End Academy"), Site, "General")) %>%
mutate(RequiredSite = sub(" .*", "", RequiredSite))
# take care of 6-th grade MS issue
students %>%
mutate(AgeBracket = ifelse(Grade == 6, "MS", AgeBracket))
# take care of 6-th grade MS issue
students = students %>%
mutate(AgeBracket = ifelse(Grade == 6, "MS", AgeBracket))
students %>%
write_csv("~/Dropbox (MIT)/ESY/Data/data/input_data/student_list.csv")
# 2019 solution
data = read_csv("~/Dropbox (MIT)/ESY/Data/data/2019_solution/esy_assignments_2019.csv", col_types = cols(ServicesOnly = col_character()))
# Student locations
locs = read_csv("~/Dropbox (MIT)/ESY/Data/data/student_locations/student_locations_full_19.csv")
# Build the student list
students = data %>%
left_join(locs, by="StudentNumber") %>%
filter(!(Site %in% c("Home", "#N/A", "None", "Custodial Site", "Wentworth University", "Digital Imaging at English High", "Goodwill Program"))) %>%
filter(is.na(ServicesOnly)) %>%
mutate(RequiredSite = ifelse(Site %in% c("Carter School", "McKinley South End Academy"), Site, "General")) %>%
mutate(RequiredSite = sub(" .*", "", RequiredSite))
students %>%
write_csv("~/Dropbox (MIT)/ESY/Data/data/input_data/student_list.csv")
# Build the restrictions list
restrictions = data.frame(
RequiredSite = c("General", "Carter", "McKinley"),
School1 = c("Carter School", "Carter School",
"McKinley South End Academy"),
School2 = c("McKinley South End Academy", "", ""),
School3 = c("", "", ""),
IncludeOrExclude = c(0, 1, 1)
)
restrictions %>%
write_csv("~/Dropbox (MIT)/ESY/Data/data/input_data/restrictions.csv")
# Build the cohort list
students %>%
filter(SN %in% c("D4", "P4", "M4", "X4", "Y4", "E4", "E3")) %>%
filter(AgeBracket %in% c("ES", "EC")) %>%
select(StudentNumber, RegularSchoolCode) %>%
write_csv("~/Dropbox (MIT)/ESY/Data/data/input_data/cohort_list.csv")
install.packages("dplyr")
install.packages('dplyr')
install.packages('rstudio')
install.packages('dplyr')
library(tidyverse)
start_date = "2020-04-16"
end_date = "2020-06-01"
### IHME Predictions
df_ihme <- read.csv("../raw_data/ihme-2020_04_13.csv", stringsAsFactors = FALSE)
setwd("~/Documents/MIT/Grad/Covid19/ventilator-allocation/src")
### IHME Predictions
df_ihme <- read.csv("../raw_data/ihme-2020_04_13.csv", stringsAsFactors = FALSE)
### IHME Predictions
df_ihme <- read.csv("../raw_data/ihme-2020_04_12.csv", stringsAsFactors = FALSE)
df_clean_ihme <- df_ihme %>%
mutate(Day = as.Date(date)) %>%
select(State = location_name,
Day,
"Hospitalizations" = allbed_mean,
"ICU" = ICUbed_mean,
"Ventilators" = InvVen_mean) %>%
mutate_if(is.numeric, round) %>%
filter(Day >= as.Date(start_date), Day < as.Date(end_date)) %>%
filter(State %in% state.name)
write.csv(df_clean_ihme, paste0("../processed/predicted_ihme/AllStates.csv"), row.names = FALSE)
